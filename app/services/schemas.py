from typing import Optional
from pydantic import BaseModel, EmailStr
from typing import List, Optional, Union
from enum import Enum
from uuid import UUID


class MetricReturnModel(BaseModel): 
    metric_name: str
    actual_value: Optional[Union[float, str, bool]] = None
    actual_value_type: str
    metric_labels: List[str] = []
    others: dict = {}  
    threshold: Optional[List[str]] = None
    threshold_score :Optional[float] = None
    personal_attributes: Optional[List[str]] = []
    attribute_labels: Optional[List[str]] = []
    metric_label: Optional[float] = None
class ActualValueDtype(Enum):
    FLOAT= "FLOAT"
    NONETYPE = "NONETYPE"
    
class EvaluationType(Enum):
    RESPONSE_TONE_EVALUATION = "RESPONSE_TONE_EVALUATION"
    DO_NOT_USE_KEYWORDS_EVALUATION = "DO_NOT_USE_KEYWORDS_EVALUATION"
    ANSWER_FLUENCY_EVALUATION = "ANSWER_FLUENCY_EVALUATION"
    COMPRESSION_SCORE_EVALUATION = "COMPRESSION_SCORE_EVALUATION"
    WORD_COUNT_LIMIT_EVALUATION = "WORD_COUNT_LIMIT_EVALUATION"
    FACTUAL_CONSISTENCY_EVALUATION = "FACTUAL_CONSISTENCY_EVALUATION"
    GRAMMATICAL_CORRECTNESS_EVALUATION = "GRAMMATICAL_CORRECTNESS_EVALUATION"
    CONCEPTUAL_SIMILARITY_EVALUATION = "CONCEPTUAL_SIMILARITY_EVALUATION"
    READABILITY_EVALUATION = "READABILITY_EVALUATION"
    COHERENCE_EVALUATION = "COHERENCE_EVALUATION" 
    CLARITY_EVALUATION = "CLARITY_EVALUATION"
    MODEL_REFUSAL_EVALUATION = "MODEL_REFUSAL_EVALUATION"
    DATA_LEAKAGE_EVALUATION = "DATA_LEAKAGE_EVALUATION"
    DIVERSITY_EVALUATION = "DIVERSITY_EVALUATION"
    CREATIVITY_EVALUATION = "CREATIVITY_EVALUATION"
    NARRATIVE_CONTINUITY_EVALUATION = "NARRATIVE_CONTINUITY_EVALUATION"
    PROMPT_INJECTION_EVALUATION = "PROMPT_INJECTION_EVALUATION"
    INSECURE_OUTPUT_EVALUATION = "INSECURE_OUTPUT_EVALUATION"
    TOXICITY_EVALUATION = "TOXICITY_EVALUATION"
    BIAS_EVALUATION = "BIAS_EVALUATION"